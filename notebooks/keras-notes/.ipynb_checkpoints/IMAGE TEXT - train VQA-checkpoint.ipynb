{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Visual Question Answering (VQA) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "- [Data download & instructions](https://github.com/VT-vision-lab/VQA_LSTM_CNN)\n",
    "- I am using the [preprocessed train-valid-test data](https://filebox.ece.vt.edu/~jiasenlu/codeRelease/vqaRelease/train_val/data_train-val_test.zip)\n",
    "- Build a model similiar to [here](https://github.com/dolaameng/deeplearning-exploration/blob/master/notebooks/USECASE%20-%20Visual%20Q%20%26%20A%20by%20Keras.ipynb)\n",
    "- Several existing implementations\n",
    "    - [VQA_LSTM_CNN - lua](https://github.com/VT-vision-lab/VQA_LSTM_CNN)\n",
    "    - [HieCoAttenVQA - lua](https://github.com/jiasenlu/HieCoAttenVQA)\n",
    "    - [VQA_Keras - python](https://github.com/iamaaditya/VQA_Keras)\n",
    "- VQA sites\n",
    "    - [VQA org](http://www.visualqa.org/)\n",
    "    - [Microsoft common objects in context (COCO)](http://mscoco.org/dataset/#download)\n",
    "- Competitions\n",
    "    - [VQA Real Image Challenge](https://competitions.codalab.org/competitions/6961#results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from https://filebox.ece.vt.edu/~jiasenlu/codeRelease/vqaRelease/train_val/data_train-val_test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3.3G\r\n",
      "-rw-rw-r-- 1 dola dola 3.2G Dec 19  2015 data_img.h5\r\n",
      "-rw-rw-r-- 1 dola dola  81M Dec 19  2015 data_prepro.h5\r\n",
      "-rw-rw-r-- 1 dola dola 8.8M Dec 19  2015 data_prepro.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ../../data/vqa_processed/train_val_test/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Understand Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "from os import path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items in image set [u'images_test', u'images_train']\n",
      "image set shapes [(u'images_test', (40504, 4096)), (u'images_train', (82459, 4096))]\n",
      "\n",
      "\n",
      "items in question set [u'MC_ans_test', u'answers', u'img_pos_test', u'img_pos_train', u'ques_length_test', u'ques_length_train', u'ques_test', u'ques_train', u'question_id_test', u'question_id_train']\n",
      "\n",
      "\n",
      "items in meta data [u'ix_to_word', u'unique_img_test', u'ix_to_ans', u'unique_img_train']\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../../data/vqa_processed/train_val/\"\n",
    "\n",
    "image_set = h5py.File(path.join(data_path, \"data_img.h5\"))\n",
    "print \"items in image set\", image_set.keys()\n",
    "print \"image set shapes\", [(k, imgs.shape) for k,imgs in image_set.items()]\n",
    "\n",
    "print \"\\n\"\n",
    "\n",
    "question_set = h5py.File(path.join(data_path, \"data_prepro.h5\"))\n",
    "print \"items in question set\", question_set.keys()\n",
    "\n",
    "print \"\\n\"\n",
    "\n",
    "meta_data = json.load(open(path.join(data_path, \"data_prepro.json\")))\n",
    "print \"items in meta data\", meta_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
