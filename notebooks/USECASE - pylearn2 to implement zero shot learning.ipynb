{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Pylearn2 to Implement word/image vector fusion\n",
    "- [source of both idea and code](https://github.com/mganjoo/zslearning)\n",
    "- [a theano based implementation] - http://nbviewer.ipython.org/github/renruoxu/data-fusion/blob/master/deprecated/mapping%20(1).ipynb\n",
    "- it is a standard 1-hidden layer MLP with customized cost function\n",
    "- the data we use here is that: X (image vectors from DeCaff), Y (word vectors from word2vec)\n",
    "\n",
    "    \n",
    "##TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Use Theanets to Implement Word/Image Vector fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theanets\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store = pd.HDFStore(\"../data/cifa_XY.hd5\")\n",
    "X = store[\"X/\"].get_values()\n",
    "y = store[\"Y/\"].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34000, 4096) (10000, 4096) (10000, 4096) (34000, 100) (10000, 100) (10000, 100)\n"
     ]
    }
   ],
   "source": [
    "train_X, other_X, train_y, other_y = train_test_split(X, y, test_size = 20000)\n",
    "valid_X, test_X, valid_y, test_y = train_test_split(other_X, other_y, test_size = 10000)\n",
    "print train_X.shape, valid_X.shape, test_X.shape, train_y.shape, valid_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss_X = StandardScaler()\n",
    "ss_X.fit(train_X)\n",
    "scaled_train_X, scaled_valid_X, scaled_test_X = ss_X.transform(train_X), ss_X.transform(valid_X), ss_X.transform(test_X)\n",
    "\n",
    "ss_y = StandardScaler()\n",
    "ss_y.fit(train_y)\n",
    "scaled_train_y, scaled_valid_y, scaled_test_y = ss_y.transform(train_y), ss_y.transform(valid_y), ss_y.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss(err) 0.501571049574 (0.337281) valid loss(err) 0.507652382711 (0.34752)\n",
      "train loss(err) 0.489599651034 (0.32475) valid loss(err) 0.507652382711 (0.34752)\n",
      "train loss(err) 0.481531395267 (0.317602) valid loss(err) 0.507652382711 (0.34752)\n",
      "train loss(err) 0.477328235284 (0.313552) valid loss(err) 0.507652382711 (0.34752)\n",
      "train loss(err) 0.47394823341 (0.310065) valid loss(err) 0.507652382711 (0.34752)\n",
      "train loss(err) 0.470216634923 (0.307241) valid loss(err) 0.48528451469 (0.320465)\n",
      "train loss(err) 0.468957066081 (0.305537) valid loss(err) 0.48528451469 (0.320465)\n",
      "train loss(err) 0.464989497482 (0.302448) valid loss(err) 0.48528451469 (0.320465)\n",
      "train loss(err) 0.463798143785 (0.301249) valid loss(err) 0.48528451469 (0.320465)\n",
      "train loss(err) 0.463392980533 (0.299902) valid loss(err) 0.48528451469 (0.320465)\n",
      "train loss(err) 0.461434469735 (0.298907) valid loss(err) 0.486342760916 (0.321613)\n",
      "train loss(err) 0.459186469714 (0.296426) valid loss(err) 0.486342760916 (0.321613)\n",
      "train loss(err) 0.457677312524 (0.29453) valid loss(err) 0.486342760916 (0.321613)\n",
      "train loss(err) 0.456516028592 (0.293596) valid loss(err) 0.486342760916 (0.321613)\n",
      "train loss(err) 0.456175427913 (0.293415) valid loss(err) 0.486342760916 (0.321613)\n",
      "train loss(err) 0.455945818725 (0.292444) valid loss(err) 0.483580504676 (0.321354)\n",
      "train loss(err) 0.453158932291 (0.290708) valid loss(err) 0.483580504676 (0.321354)\n",
      "train loss(err) 0.452858635377 (0.289373) valid loss(err) 0.483580504676 (0.321354)\n",
      "train loss(err) 0.452184333238 (0.289231) valid loss(err) 0.483580504676 (0.321354)\n",
      "train loss(err) 0.450493838677 (0.287265) valid loss(err) 0.483580504676 (0.321354)\n"
     ]
    }
   ],
   "source": [
    "#exp.train((scaled_train_X, scaled_train_y), (scaled_valid_X, scaled_valid_y), \n",
    "#          optimize = \"sgd\", learning_rate = 0.005)\n",
    "for train, valid in exp.itertrain(train_set = (scaled_train_X, scaled_train_y), \n",
    "                                  valid_set = (scaled_valid_X, scaled_valid_y), \n",
    "                                  optimize = \"sgd\", learning_rate = 0.005, validate_every = 5,\n",
    "                                     hidden_l1 = 0.01, weight_l2 = 1e-4):\n",
    "    print 'train loss(err)', train['loss'], \"(%g)\" % train[\"err\"], 'valid loss(err)', valid['loss'], \"(%g)\" % valid['err']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32957093927984654"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(exp.network.predict(scaled_test_X), scaled_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.53 s, sys: 0 ns, total: 2.53 s\n",
      "Wall time: 2.47 s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "%time model = Word2Vec.load_word2vec_format(\"../data/word2vec.bin\", binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = [\"airplane\", \"automobile\", \"bird\",\"cat\",\"deer\",\"dog\",\"frog\", \"horse\", \"ship\",\"truck\"]\n",
    "vec = []\n",
    "for word in words:\n",
    "    vec.append(model[word])\n",
    "vec_word = zip(vec,words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels_test = np.zeros((test_y.shape[0],)).astype(str)\n",
    "for i in xrange(test_y.shape[0]):\n",
    "    for j in xrange(len(vec_word)):\n",
    "        if np.allclose(vec_word[j][0], test_y[i]):\n",
    "            labels_test[i] = vec_word[j][1]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'horse': 1048, 'ship': 1040, 'frog': 1009, 'bird': 1009, 'deer': 997, 'airplane': 995, 'cat': 987, 'truck': 981, 'dog': 975, 'automobile': 959})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100)\n",
      "CPU times: user 2.74 ms, sys: 3.03 ms, total: 5.77 ms\n",
      "Wall time: 5.78 ms\n",
      "(10000, 10)\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "pred_scores = exp.network.predict(scaled_test_X)\n",
    "print pred_scores.shape\n",
    "%time dist = pairwise_distances(pred_scores,ss_y.transform(vec), metric=\"euclidean\")\n",
    "print dist.shape\n",
    "pred = np.argmin(dist,axis=1)\n",
    "pred = [words[i] for i in pred]\n",
    "print len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7813\n",
      "[[771  17  46  11  17   4   7  13  84  25]\n",
      " [ 24 840   4   2   1   1   5   0  10  72]\n",
      " [ 38   3 729  65  67  37  41  20   8   1]\n",
      " [ 12   9  61 647  35 119  63  30   7   4]\n",
      " [ 17   2  63  54 722  20  59  54   4   2]\n",
      " [  5   3  32 151  24 708  19  26   4   3]\n",
      " [ 12   2  38  56  31  16 838   4   5   7]\n",
      " [ 12   4  22  82  41  54   6 802   8  17]\n",
      " [ 54  19   8   8   5   4   2   4 895  41]\n",
      " [ 20  39   2   8   3   3  10  18  17 861]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print accuracy_score(labels_test,pred)\n",
    "print confusion_matrix(labels_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_labels = pairwise_distances_argmin(y, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 4096) (54000, 100)\n"
     ]
    }
   ],
   "source": [
    "nodog = (y_labels != 8)\n",
    "nodog_X, nodog_y = X[nodog], y[nodog]\n",
    "print nodog_X.shape, nodog_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = nodog_X\n",
    "y = nodog_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store = pd.HDFStore(\"../data/cifa_XY.hd5\")\n",
    "X = store[\"X/\"].get_values()\n",
    "y = store[\"Y/\"].get_values()\n",
    "dog_X = ss_X.transform(X[~nodog])\n",
    "dog_X_labels = pairwise_distances_argmin(exp.network.predict(dog_X), ss_y.transform(vec))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'airplane': 4165, 'truck': 905, 'automobile': 597, 'cat': 99, 'bird': 98, 'deer': 42, 'horse': 38, 'frog': 28, 'dog': 19, 'ship': 9})"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(np.array(words)[dog_X_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
