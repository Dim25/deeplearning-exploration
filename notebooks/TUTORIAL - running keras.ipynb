{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Framework based on theano\n",
    "- [github](https://github.com/fchollet/keras)\n",
    "- [website](http://keras.io/)\n",
    "- [examples showing off modelling capability](http://keras.io/examples/)\n",
    "- [example codes on image/text data](https://github.com/fchollet/keras/tree/master/examples)\n",
    "\n",
    "### Philosophy\n",
    "- fast prototyping with flexible and minimal configuration: Torch like interface within Python, also supports sklearn-like prediction interface, e.g., `fit`, `train_on_batch`, `evaluate`, `predict_classes`, `predict_proba`.\n",
    "- run on both cpu and gpu\n",
    "- support both convotlutional networks and recurrent networks\n",
    "- easy to extend\n",
    "\n",
    "### Basic Usage\n",
    "Like almost all other apis, the main compoents of keras are (1) different types of layers (2) model (net) consisting of layers and a loss function, (3) optimizers and optionally some data-processing facilities e.g. for image/text/sequence data. \n",
    "\n",
    "### Main APIS\n",
    "\n",
    "#### A. Data Processing - most of them are helper functions, and helper processors\n",
    "- packages: \n",
    "    - `keras.preprocessing.sequence` for sequence data\n",
    "    - `keras.preprocessing.text` for text data\n",
    "    - `keras.preprocessing.image` for image data\n",
    "\n",
    "#### B. Layers\n",
    "- packages:\n",
    "    - `keras.layers.core` for core layers\n",
    "    - `keras.layers.convolutional` for convolution/pooling layers\n",
    "    - `keras.layers.recurrent` for recurrent layers\n",
    "    - `keras.layers.advanced_activations` as its name suggests\n",
    "    - `keras.layers.normalization` for normalizations\n",
    "    - `keras.layers.embeddings` for text embedding (vector representation)\n",
    "    - `keras.layers.noise` for noise-adding\n",
    "    - `keras.layers.containers` for ensemble/composite layers, e.g. sequentially stacked multilayers\n",
    "- activation functions: activations of layers can be specified (1) either via a separate activation layer or (2) through the activation argument supported by all forward layers.Existing activations are\n",
    "    - softmax: expect shape to be either (nsamples, ntimesteps, ndims) or (nsamples, ndims)\n",
    "    - softplus\n",
    "    - relu\n",
    "    - tanh\n",
    "    - sigmoid\n",
    "    - hard_sigmoid\n",
    "    - linear\n",
    "- initialization of layer weights can be specified by `init` param in the layer construtor, out-of-box initialization include\n",
    "    - uniform\n",
    "    - lecun_uniform (uniform initialization scaled by sqrt of nins)\n",
    "    - normal\n",
    "    - identity \n",
    "    - orthogonal\n",
    "    - zero\n",
    "    - glorot_normal (Gaussian initialization scaled by nin+nout)\n",
    "    - glorot_uniform\n",
    "    - he_normal\n",
    "    - he_uniform\n",
    "- regularization of layer weights: they are either on layer weights and/or layer activations. These are done via three parameters to a layer. The parameters can have different regularizer instances from the `keras.regularizers` package.\n",
    "    - `W_regularizer`: l1(l=0.01), l2(l=0.01), l1l2(l1=0.01, l2=0.01)\n",
    "    - `b_regularizer`: l1(l=0.01), l2(l=0.01), l1l2(l1=0.01, l2=0.01)\n",
    "    - `activity_regularizer`: activity_l1(l=0.01), activity_l2(l=0.01), activity_l1l2(l1=0.01, l2=0.01)\n",
    "- constraints: some layers need constraints, see [doc](http://keras.io/constraints/) for details\n",
    "\n",
    "#### C. Objective Functions\n",
    "Objective functions can be specifed either by name (see below the out-of-box objective function names) or a Theano symbolic function that returns a scalar for each data point - exmaples can be found in [source code](https://github.com/fchollet/keras/blob/master/keras/objectives.py). Available functions include,\n",
    "- mean_squared_error / mse\n",
    "- mean_absolute_error / mae\n",
    "- mean_absolute_percentage_error / mape\n",
    "- mean_squared_logarithmic_error / msle\n",
    "- squared_hinge: only for binary classification\n",
    "- hinge: only for binary classification\n",
    "- binary_crossentropy: Also known as logloss.\n",
    "- categorical_crossentropy: aka softmax for multi-classification. ***It needs the labels are in one-hot-encoding, i.e., binary arrays of shape (nsamples, nclasses)***\n",
    "\n",
    "#### D. Optimizers \n",
    "Existing optimizers and their parameters can be found in the [doc](http://keras.io/optimizers/)\n",
    "\n",
    "#### E. Callback functors\n",
    "Callback functors are subclasses of `keras.callbacks.Callback` with specific event slots such as `on_train_begin/end(logs={})`, `on_epoch_begin/end(epoch, logs={})`, `on_batch_begin/end(batch, logs={})`. The commonly used out-of-box callbacks are \n",
    "- `ModelCheckpoint(filepath, verbose = 0, save_best_only=False)`: Save the model after every epoch. If save_best_only=True, the latest best model according to the validation loss will not be overwritten.\n",
    "- `EarlyStopping(monitor='val_loss', patience=0, verbose=0)`: Stop training after no improvement of the metric monitor is seen for patience epochs. The parameter of monitor is a key in the `logs` dictionary passed into event listeners.\n",
    "\n",
    "#### F. Models\n",
    "- it is the main access point for training/evaluating. \n",
    "- it assembles other components such as layers, objective functions and optimizers, e.g.,\n",
    "    - add layer by `model.add`\n",
    "    - set loss function and optimizer in `model.compile`\n",
    "    - set callback functions in `model.fit`\n",
    "- specify callback functions at different stages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
