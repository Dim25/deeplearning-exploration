{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Use Scinarios for Deep Learning Models\n",
    "### 1. Building Models on Training Data\n",
    "1. Customize Network Layout: e.g., number of layers, connections, activation functions, weight initializations\n",
    "2. Customize Cost Function: special regularization\n",
    "3. Choose or Customize optimization method, e.g., l-bfgs, cg, batch-gd, sgd, etc.\n",
    "4. Specify early stopping, train/validation data, performance monitoring\n",
    "5. Save learned weights and be able to recover from it\n",
    "### 2. Use Models on New Data\n",
    "1. Restore model from its trained weights and yaml configuration\n",
    "2. Predict on new data\n",
    "3. Extract weights from hidden layers as features - mostly only useful for models pre-trained on large data, e.g., Caffe, Overfeat, sklearn-theano\n",
    "\n",
    "\n",
    "**we will try to cover these points in this notebook**\n",
    "**use the [data-downloading script](https://github.com/lisa-lab/DeepLearningTutorials/blob/master/data/download.sh) to download the necessary data into `./data` folder** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pylearn2 for Deep Learning\n",
    "1. pylearn2 to Theano is similiar as scipy to numpy\n",
    "2. it utilizes yaml for quick experiemnt setup, under a unified framework including `dataset`, `algorithm`(optimizer), `model` (network), which are leigo blocks for deep leanring\n",
    "3. in the yaml configuration, you can use `!obj:` to create instance (composite of both data and methods), `!import` to attach to customized functions (e.g., cost function), and `!pkl:` to load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\r\n",
      "Metadata-Version: 1.0\r\n",
      "Name: pylearn2\r\n",
      "Version: 0.1.dev0\r\n",
      "Summary: A machine learning library built on top of Theano.\r\n",
      "Home-page: UNKNOWN\r\n",
      "Author: UNKNOWN\r\n",
      "Author-email: UNKNOWN\r\n",
      "License: BSD 3-clause license\r\n",
      "Location: /home/dola/opt/pylearn2\r\n",
      "Requires: numpy, pyyaml, argparse, Theano\r\n"
     ]
    }
   ],
   "source": [
    "!pip show pylearn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from pylearn2.config import yaml_parse\n",
    "from pylearn2.datasets import DenseDesignMatrix\n",
    "import cPickle\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [Basic Example of Building Softmax Regression for MNIST - with YAML](http://nbviewer.ipython.org/github/lisa-lab/pylearn2/blob/master/pylearn2/scripts/tutorials/softmax_regression/softmax_regression.ipynb)\n",
    "\n",
    "**The exercise focuses on how easy or hard to quickly test a model on an numpy.array in pylearn2**\n",
    "\n",
    "**its use feels quite counter-intuitive for explorative data science - it needs to force everything into YAML and dump everything on disk first - Theano has a much more friendly interface when integrated with other python objects in this case**\n",
    "\n",
    "**but pylearn2 may have its point of doing this as it uses configuration to train pre-defined data to get good performance, but not necessarily in an explorative environment**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## prepare data - from single mnist.pkl to create training, valiadtion and testing set and pickle them\n",
    "## even though pylearn2.datasets.DenseDesignMatrix accepts integer array as y, but SoftmaxRegression Model\n",
    "## only accepts one-hot encoding\n",
    "mnist_data_config = r\"!pkl: '../data/mnist.pkl'\"\n",
    "train_mnist, valid_mnist, test_mnist = yaml_parse.load(mnist_data_config)\n",
    "coder = preprocessing.OneHotEncoder()\n",
    "train_mnist = DenseDesignMatrix(X = train_mnist[0], y = coder.fit_transform(train_mnist[1].reshape((-1, 1))).toarray())\n",
    "valid_mnist = DenseDesignMatrix(X = valid_mnist[0], y = coder.fit_transform(valid_mnist[1].reshape((-1, 1))).toarray())\n",
    "test_mnist = DenseDesignMatrix(X = test_mnist[0], y = coder.fit_transform(test_mnist[1].reshape((-1, 1))).toarray())\n",
    "cPickle.dump(train_mnist, open(\"../data/train_mnist.pkl\", \"w\"))\n",
    "cPickle.dump(valid_mnist, open(\"../data/valid_mnist.pkl\", \"w\"))\n",
    "cPickle.dump(test_mnist, open(\"../data/test_mnist.pkl\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atis.fold0.pkl.gz  atis.fold4.pkl.gz  mnist.pkl.gz\t test_mnist.pkl\r\n",
      "atis.fold1.pkl.gz  imdb.pkl\t      mnist_py3k.pkl.gz  train_mnist.pkl\r\n",
      "atis.fold2.pkl.gz  midi.zip\t      Nottingham\t valid_mnist.pkl\r\n",
      "atis.fold3.pkl.gz  mnist.pkl\t      Nottingham.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_config = r\"\"\"&train !pkl: '../data/train_mnist.pkl'\n",
    "\"\"\"\n",
    "\n",
    "model_config = r\"\"\"!obj:pylearn2.models.softmax_regression.SoftmaxRegression {\n",
    "  n_classes: 10,\n",
    "  irange: 0.,\n",
    "  nvis: 784\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "algorithm_config = r\"\"\"!obj:pylearn2.training_algorithms.bgd.BGD {\n",
    "  batch_size: 10000,\n",
    "  conjugate: 1,\n",
    "  monitoring_dataset: {\n",
    "    'train': *train,\n",
    "    'valid': !pkl: '../data/valid_mnist.pkl'\n",
    "  },\n",
    "  termination_criterion: !obj:pylearn2.termination_criteria.MonitorBased {\n",
    "    channel_name: \"valid_y_misclass\"\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "driver_config = r\"\"\"!obj:pylearn2.train.Train {\n",
    "  dataset: %s\n",
    "  , model: %s\n",
    "  , algorithm: %s\n",
    "  , extensions: [!obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {\n",
    "             channel_name: 'valid_y_misclass',\n",
    "             save_path: \"../models/softmax_regression_best.pkl\"\n",
    "        },]\n",
    "  , save_path: \"../models/softmax_regression.pkl\"\n",
    "  , save_freq: 1\n",
    "}\n",
    "\"\"\" % (dataset_config, model_config, algorithm_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/dola/.theano/compiledir_Linux-3.13--generic-x86_64-with-Ubuntu-14.04-trusty-x86_64-2.7.6-64/lock_dir/lock\n",
      "INFO:theano.gof.compilelock:Refreshing lock /home/dola/.theano/compiledir_Linux-3.13--generic-x86_64-with-Ubuntu-14.04-trusty-x86_64-2.7.6-64/lock_dir/lock\n"
     ]
    }
   ],
   "source": [
    "%%capture log\n",
    "driver = yaml_parse.load(driver_config)\n",
    "driver.main_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9996146\n",
      "\tvalid_y_mean_max_class: 0.917966512741\n",
      "\tvalid_y_min_max_class: 0.248488289737\n",
      "\tvalid_y_misclass: 0.0714\n",
      "\tvalid_y_nll: 0.261678336848\n",
      "\tvalid_y_row_norms_max: 1.99803194598\n",
      "\tvalid_y_row_norms_mean: 0.574710145358\n",
      "\tvalid_y_row_norms_min: 0.0\n",
      "Saving to ../models/softmax_regression.pkl...\n",
      "Saving to ../models/softmax_regression.pkl done. Time elapsed: 0.015478 seconds\n",
      "Saving to ../models/softmax_regression.pkl...\n",
      "Saving to ../models/softmax_regression.pkl done. Time elapsed: 0.013851 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print log.stdout[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " classification rate on test data 0.924\n"
     ]
    }
   ],
   "source": [
    "## make use of trained model\n",
    "## You need to do all the geeky stuff here to convert it back to Theano\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import numpy as np \n",
    "softmax_model = cPickle.load(open(\"../models/softmax_regression.pkl\"))\n",
    "X = softmax_model.get_input_space().make_theano_batch()\n",
    "y = softmax_model.fprop(X)\n",
    "ylabel = T.argmax(y, axis = 1)\n",
    "predict = theano.function([X], ylabel)\n",
    "\n",
    "yhat = predict(test_mnist.X)\n",
    "ytarget = cPickle.load(open(\"../data/mnist.pkl\"))[-1][1]\n",
    "print \"classification rate on test data\", np.mean(yhat == ytarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. [stacked autoencoders example by yaml](http://nbviewer.ipython.org/github/lisa-lab/pylearn2/blob/master/pylearn2/scripts/tutorials/stacked_autoencoders/stacked_autoencoders.ipynb)\n",
    "\n",
    "1. layerwise pre-training (unsupervised) for denoising autoencoder\n",
    "2. stacking these layers to form a MLP and fine tune it with supverised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture log\n",
    "\n",
    "## layer 1 - unsupervised training\n",
    "layer1_yaml = r\"\"\"\n",
    "!obj:pylearn2.train.Train {\n",
    "    dataset: &train !pkl: '../data/train_mnist.pkl',\n",
    "    model: !obj:pylearn2.models.autoencoder.DenoisingAutoencoder {\n",
    "        nvis : 784,\n",
    "        nhid : 500,\n",
    "        irange : 0.05,\n",
    "        corruptor: !obj:pylearn2.corruption.BinomialCorruptor {\n",
    "            corruption_level: .2,\n",
    "        },\n",
    "        act_enc: \"tanh\",\n",
    "        act_dec: null,    # Linear activation on the decoder side.\n",
    "    },\n",
    "    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {\n",
    "        learning_rate : 1e-3,\n",
    "        batch_size : 100,\n",
    "        monitoring_batches : 5,\n",
    "        monitoring_dataset : *train,\n",
    "        cost : !obj:pylearn2.costs.autoencoder.MeanSquaredReconstructionError {},\n",
    "        termination_criterion : !obj:pylearn2.termination_criteria.EpochCounter {\n",
    "            max_epochs: 10,\n",
    "        },\n",
    "    },\n",
    "    save_path: \"../models/dae_l1.pkl\",\n",
    "    save_freq: 1\n",
    "}\n",
    "\"\"\"\n",
    "layer1 = yaml_parse.load(layer1_yaml)\n",
    "\n",
    "\n",
    "layer1.main_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to ../models/dae_l1.pkl done. Time elapsed: 0.756267 seconds\n",
      "Time this epoch: 8.580836 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 10\n",
      "\tBatches seen: 5000\n",
      "\tExamples seen: 500000\n",
      "\tlearning_rate: 0.001\n",
      "\tobjective: 11.8870911208\n",
      "\ttotal_seconds_last_epoch: 13.212896\n",
      "\ttraining_seconds_this_epoch: 8.580836\n",
      "Saving to ../models/dae_l1.pkl...\n",
      "Saving to ../models/dae_l1.pkl done. Time elapsed: 0.764984 seconds\n",
      "Saving to ../models/dae_l1.pkl...\n",
      "Saving to ../models/dae_l1.pkl done. Time elapsed: 0.751901 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print log.stdout[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture log\n",
    "## second layer trainning - 2nd layer takes the output of the 1st layer as its input\n",
    "layer2_yaml = r\"\"\"!obj:pylearn2.train.Train {\n",
    "    dataset: &train !obj:pylearn2.datasets.transformer_dataset.TransformerDataset {\n",
    "        raw: !pkl: '../data/train_mnist.pkl',\n",
    "        transformer: !pkl: \"../models/dae_l1.pkl\" # use layer 1 as input\n",
    "    },\n",
    "    model: !obj:pylearn2.models.autoencoder.DenoisingAutoencoder {\n",
    "        nvis : 500,\n",
    "        nhid : 500,\n",
    "        irange : 0.05,\n",
    "        corruptor: !obj:pylearn2.corruption.BinomialCorruptor {\n",
    "            corruption_level: .3,\n",
    "        },\n",
    "        act_enc: \"tanh\",\n",
    "        act_dec: null,    # Linear activation on the decoder side.\n",
    "    },\n",
    "    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {\n",
    "        learning_rate : 1e-3,\n",
    "        batch_size : 100,\n",
    "        monitoring_batches : 5,\n",
    "        monitoring_dataset : *train,\n",
    "        cost : !obj:pylearn2.costs.autoencoder.MeanSquaredReconstructionError {},\n",
    "        termination_criterion : !obj:pylearn2.termination_criteria.EpochCounter {\n",
    "            max_epochs: 10,\n",
    "        },\n",
    "    },\n",
    "    save_path: \"../models/dae_l2.pkl\",\n",
    "    save_freq: 1\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "layer2 = yaml_parse.load(layer2_yaml)\n",
    "\n",
    "\n",
    "layer2.main_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o ../models/dae_l2.pkl done. Time elapsed: 0.415859 seconds\n",
      "Time this epoch: 12.082077 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 10\n",
      "\tBatches seen: 5000\n",
      "\tExamples seen: 500000\n",
      "\tlearning_rate: 0.001\n",
      "\tobjective: 4.3132512472\n",
      "\ttotal_seconds_last_epoch: 16.162168\n",
      "\ttraining_seconds_this_epoch: 12.082077\n",
      "Saving to ../models/dae_l2.pkl...\n",
      "Saving to ../models/dae_l2.pkl done. Time elapsed: 0.419657 seconds\n",
      "Saving to ../models/dae_l2.pkl...\n",
      "Saving to ../models/dae_l2.pkl done. Time elapsed: 0.381002 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print log.stdout[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture log\n",
    "## supervised tuning of the stacked network\n",
    "## 1. stack the two DAE into a MLP\n",
    "## supervised-training the MLP\n",
    "\n",
    "mlp_yaml = r\"\"\"!obj:pylearn2.train.Train {\n",
    "    dataset: &train !pkl: '../data/train_mnist.pkl',\n",
    "    model: !obj:pylearn2.models.mlp.MLP {\n",
    "        batch_size: 100,\n",
    "        layers: [\n",
    "                 !obj:pylearn2.models.mlp.PretrainedLayer {\n",
    "                     layer_name: 'h1',\n",
    "                     layer_content: !pkl: \"../models/dae_l1.pkl\"\n",
    "                 },\n",
    "                 !obj:pylearn2.models.mlp.PretrainedLayer {\n",
    "                     layer_name: 'h2',\n",
    "                     layer_content: !pkl: \"../models/dae_l2.pkl\"\n",
    "                 },\n",
    "                 !obj:pylearn2.models.mlp.Softmax {\n",
    "                     max_col_norm: 1.9365,\n",
    "                     layer_name: 'y',\n",
    "                     n_classes: 10,\n",
    "                     irange: .005\n",
    "                 }\n",
    "                ],\n",
    "        nvis: 784\n",
    "    },\n",
    "    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {\n",
    "        learning_rate: .05,\n",
    "        learning_rule: !obj:pylearn2.training_algorithms.learning_rule.Momentum {\n",
    "            init_momentum: .5,\n",
    "        },\n",
    "        monitoring_dataset:\n",
    "            {\n",
    "                'valid' : !pkl: '../data/valid_mnist.pkl',\n",
    "            },\n",
    "        cost: !obj:pylearn2.costs.mlp.Default {},\n",
    "        termination_criterion: !obj:pylearn2.termination_criteria.And {\n",
    "            criteria: [\n",
    "                !obj:pylearn2.termination_criteria.MonitorBased {\n",
    "                    channel_name: \"valid_y_misclass\",\n",
    "                    prop_decrease: 0.,\n",
    "                    N: 100\n",
    "                },\n",
    "                !obj:pylearn2.termination_criteria.EpochCounter {\n",
    "                    max_epochs: 50\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        update_callbacks: !obj:pylearn2.training_algorithms.sgd.ExponentialDecay {\n",
    "            decay_factor: 1.00004,\n",
    "            min_lr: .000001\n",
    "        }\n",
    "    },\n",
    "    extensions: [\n",
    "        !obj:pylearn2.training_algorithms.learning_rule.MomentumAdjustor {\n",
    "            start: 1,\n",
    "            saturate: 250,\n",
    "            final_momentum: .7\n",
    "        }\n",
    "    ],\n",
    "    save_path: \"../models/mlp.pkl\",\n",
    "    save_freq: 1\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "mlp_yaml = yaml_parse.load(mlp_yaml)\n",
    "\n",
    "\n",
    "mlp_yaml.main_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 1.93520071282\n",
      "\tvalid_y_max_max_class: 0.999997682992\n",
      "\tvalid_y_mean_max_class: 0.98003508451\n",
      "\tvalid_y_min_max_class: 0.548868565573\n",
      "\tvalid_y_misclass: 0.0203\n",
      "\tvalid_y_nll: 0.0668058268363\n",
      "\tvalid_y_row_norms_max: 0.545912116268\n",
      "\tvalid_y_row_norms_mean: 0.264345579985\n",
      "\tvalid_y_row_norms_min: 0.101699705657\n",
      "Saving to ../models/mlp.pkl...\n",
      "Saving to ../models/mlp.pkl done. Time elapsed: 0.958934 seconds\n",
      "Saving to ../models/mlp.pkl...\n",
      "Saving to ../models/mlp.pkl done. Time elapsed: 0.955979 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print log.stdout[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data:  0.98\n"
     ]
    }
   ],
   "source": [
    "## make use of trained model\n",
    "## You need to do all the geeky stuff here to convert it back to Theano\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "softmax_model = cPickle.load(open(\"../models/mlp.pkl\"))\n",
    "X = softmax_model.get_input_space().make_theano_batch()\n",
    "y = softmax_model.fprop(X)\n",
    "ylabel = T.argmax(y, axis = 1)\n",
    "predict = theano.function([X], ylabel)\n",
    "\n",
    "yhat = predict(test_mnist.X)\n",
    "ytarget = cPickle.load(open(\"../data/mnist.pkl\"))[-1][1]\n",
    "print \"Accuracy on test data: \", np.mean(yhat == ytarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. So I need a wrapper for current pylearn2 \n",
    "\n",
    "**support sklearn-like interface and handle data dumping behind the scene, it is a direct wrapper that still supports yaml language**\n",
    "\n",
    "### it supports two type of pylearn2 model \n",
    "- single configuration model that can be trained by a specific algorithm, e.g., MLP\n",
    "- stacked models that should be trained stage by stage, e.g., Stacked Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path += [\"../python-codes/\"]\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sklearn_pylearn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TUTORIAL - pylearn2 101.ipynb  TUTORIAL - sklearn-theano.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted /home/dola/workspace/dola/deeplearning-exploration/notebooks/testmodel-Apr222015-160837\n"
     ]
    }
   ],
   "source": [
    "m = sklearn_pylearn2.Pylearn2Model(\"testmodel\", None, None)\n",
    "m.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
