{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Theanets to Implement Word/Image Vector fusion\n",
    "- [source of both idea and code](https://github.com/mganjoo/zslearning)\n",
    "- [a theano based implementation] - http://nbviewer.ipython.org/github/renruoxu/data-fusion/blob/master/deprecated/mapping%20(1).ipynb\n",
    "- it is a standard 1-hidden layer MLP with customized cost function\n",
    "- the data we use here is that: X (image vectors from DeCaff), Y (word vectors from word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theanets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, pairwise_distances_argmin, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LABELS = np.array([\"airplane\", \"automobile\", \"bird\",\"cat\",\n",
    "                        \"deer\",\"dog\",\"frog\", \"horse\", \"ship\",\"truck\"])\n",
    "word2vec = Word2Vec.load_word2vec_format(\"../data/word2vec.bin\", binary = True)\n",
    "label_vecs = np.vstack([word2vec[w] for w in LABELS],)\n",
    "\n",
    "store = pd.HDFStore(\"../data/cifa_XY.hd5\")\n",
    "X = store[\"X/\"].get_values()\n",
    "y = store[\"Y/\"].get_values()\n",
    "labels = pairwise_distances_argmin(y, label_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## we train a mapping model with data excluding trucks\n",
    "## and later test whether the truck images are correctly mapped to word truck\n",
    "\n",
    "truck_index = (labels == 9) ## 5 is dog in LABELS, 9 is truck\n",
    "X_notruck, y_notruck = X[~truck_index], y[~truck_index]\n",
    "X_truck, y_truck= X[truck_index], y[truck_index]\n",
    "label_notruck, label_truck = labels[~truck_index], labels[truck_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss(err) 1.63725567084 (0.589381) valid loss(err) 3.59682703396 (2.27917)\n",
      "train loss(err) 1.29476741721 (0.434238) valid loss(err) 3.59682703396 (2.27917)\n",
      "train loss(err) 1.14287490996 (0.396441) valid loss(err) 3.59682703396 (2.27917)\n",
      "train loss(err) 1.03678626229 (0.373359) valid loss(err) 3.59682703396 (2.27917)\n",
      "train loss(err) 0.958347991959 (0.35711) valid loss(err) 3.59682703396 (2.27917)\n",
      "train loss(err) 0.896924026019 (0.344361) valid loss(err) 0.9409754833 (0.364293)\n",
      "train loss(err) 0.847685098418 (0.333805) valid loss(err) 0.9409754833 (0.364293)\n",
      "train loss(err) 0.808607263705 (0.325642) valid loss(err) 0.9409754833 (0.364293)\n",
      "train loss(err) 0.775400124158 (0.318583) valid loss(err) 0.9409754833 (0.364293)\n",
      "train loss(err) 0.746353911948 (0.312587) valid loss(err) 0.9409754833 (0.364293)\n",
      "train loss(err) 0.719666413906 (0.306712) valid loss(err) 0.755750297344 (0.332407)\n",
      "train loss(err) 0.696232671611 (0.301982) valid loss(err) 0.755750297344 (0.332407)\n",
      "train loss(err) 0.675504187836 (0.297361) valid loss(err) 0.755750297344 (0.332407)\n",
      "train loss(err) 0.656629986921 (0.292956) valid loss(err) 0.755750297344 (0.332407)\n",
      "train loss(err) 0.641158311339 (0.290005) valid loss(err) 0.755750297344 (0.332407)\n",
      "train loss(err) 0.625664807517 (0.284755) valid loss(err) 0.667962998386 (0.320867)\n",
      "train loss(err) 0.613551578682 (0.28151) valid loss(err) 0.667962998386 (0.320867)\n",
      "train loss(err) 0.602405556975 (0.278153) valid loss(err) 0.667962998386 (0.320867)\n",
      "train loss(err) 0.591715611287 (0.273999) valid loss(err) 0.667962998386 (0.320867)\n",
      "train loss(err) 0.582868841488 (0.270272) valid loss(err) 0.667962998386 (0.320867)\n",
      "train loss(err) 0.575551926772 (0.267765) valid loss(err) 0.619659461957 (0.309065)\n",
      "train loss(err) 0.567296047431 (0.263959) valid loss(err) 0.619659461957 (0.309065)\n",
      "train loss(err) 0.560579002947 (0.261204) valid loss(err) 0.619659461957 (0.309065)\n",
      "train loss(err) 0.554819863803 (0.258921) valid loss(err) 0.619659461957 (0.309065)\n",
      "train loss(err) 0.54947633987 (0.256347) valid loss(err) 0.619659461957 (0.309065)\n",
      "train loss(err) 0.543444296024 (0.253324) valid loss(err) 0.601074818507 (0.30502)\n",
      "train loss(err) 0.539060490062 (0.252059) valid loss(err) 0.601074818507 (0.30502)\n",
      "train loss(err) 0.534301395307 (0.249371) valid loss(err) 0.601074818507 (0.30502)\n",
      "train loss(err) 0.530124838358 (0.24765) valid loss(err) 0.601074818507 (0.30502)\n",
      "train loss(err) 0.525460496226 (0.245843) valid loss(err) 0.601074818507 (0.30502)\n",
      "train loss(err) 0.521737165069 (0.244288) valid loss(err) 0.574972610676 (0.293468)\n",
      "train loss(err) 0.517669851389 (0.242812) valid loss(err) 0.574972610676 (0.293468)\n",
      "train loss(err) 0.514400107427 (0.242067) valid loss(err) 0.574972610676 (0.293468)\n",
      "train loss(err) 0.510692543624 (0.239979) valid loss(err) 0.574972610676 (0.293468)\n",
      "train loss(err) 0.506670750138 (0.238982) valid loss(err) 0.574972610676 (0.293468)\n",
      "train loss(err) 0.50242639303 (0.237407) valid loss(err) 0.561212275142 (0.293152)\n",
      "train loss(err) 0.499404253212 (0.23649) valid loss(err) 0.561212275142 (0.293152)\n",
      "train loss(err) 0.494917368114 (0.235088) valid loss(err) 0.561212275142 (0.293152)\n",
      "train loss(err) 0.492675193137 (0.234381) valid loss(err) 0.561212275142 (0.293152)\n",
      "train loss(err) 0.488563709834 (0.232761) valid loss(err) 0.561212275142 (0.293152)\n",
      "train loss(err) 0.485192849719 (0.231955) valid loss(err) 0.544708604346 (0.291588)\n",
      "train loss(err) 0.482063803524 (0.230939) valid loss(err) 0.544708604346 (0.291588)\n",
      "train loss(err) 0.478841832053 (0.229737) valid loss(err) 0.544708604346 (0.291588)\n",
      "train loss(err) 0.475843887959 (0.228649) valid loss(err) 0.544708604346 (0.291588)\n",
      "train loss(err) 0.472871524852 (0.227219) valid loss(err) 0.544708604346 (0.291588)\n",
      "train loss(err) 0.47081468014 (0.226641) valid loss(err) 0.534858075848 (0.291473)\n",
      "train loss(err) 0.467444871367 (0.225233) valid loss(err) 0.534858075848 (0.291473)\n",
      "train loss(err) 0.465475719733 (0.223953) valid loss(err) 0.534858075848 (0.291473)\n",
      "train loss(err) 0.464132498414 (0.223375) valid loss(err) 0.534858075848 (0.291473)\n",
      "train loss(err) 0.462280936001 (0.222387) valid loss(err) 0.534858075848 (0.291473)\n",
      "train loss(err) 0.461114913182 (0.221747) valid loss(err) 0.523704563852 (0.284082)\n",
      "train loss(err) 0.458327876477 (0.219868) valid loss(err) 0.523704563852 (0.284082)\n",
      "train loss(err) 0.45679304346 (0.218834) valid loss(err) 0.523704563852 (0.284082)\n",
      "train loss(err) 0.456090214626 (0.218923) valid loss(err) 0.523704563852 (0.284082)\n",
      "train loss(err) 0.454056174431 (0.217455) valid loss(err) 0.523704563852 (0.284082)\n",
      "train loss(err) 0.453680684459 (0.21746) valid loss(err) 0.523270101457 (0.285956)\n",
      "train loss(err) 0.452535866759 (0.216569) valid loss(err) 0.523270101457 (0.285956)\n",
      "train loss(err) 0.451426385859 (0.215602) valid loss(err) 0.523270101457 (0.285956)\n",
      "train loss(err) 0.450389063855 (0.215275) valid loss(err) 0.523270101457 (0.285956)\n",
      "train loss(err) 0.449149770236 (0.214284) valid loss(err) 0.523270101457 (0.285956)\n",
      "train loss(err) 0.448862147008 (0.214188) valid loss(err) 0.515488999617 (0.281287)\n",
      "train loss(err) 0.446120697534 (0.212552) valid loss(err) 0.515488999617 (0.281287)\n",
      "train loss(err) 0.446177977027 (0.212831) valid loss(err) 0.515488999617 (0.281287)\n",
      "train loss(err) 0.4442186741 (0.211308) valid loss(err) 0.515488999617 (0.281287)\n",
      "train loss(err) 0.44486991654 (0.211557) valid loss(err) 0.515488999617 (0.281287)\n",
      "train loss(err) 0.443889443535 (0.211221) valid loss(err) 0.515018962391 (0.280243)\n",
      "train loss(err) 0.441856828189 (0.209696) valid loss(err) 0.515018962391 (0.280243)\n",
      "train loss(err) 0.44133168713 (0.209502) valid loss(err) 0.515018962391 (0.280243)\n",
      "train loss(err) 0.441076831156 (0.20937) valid loss(err) 0.515018962391 (0.280243)\n",
      "train loss(err) 0.439579288828 (0.208516) valid loss(err) 0.515018962391 (0.280243)\n",
      "train loss(err) 0.439120246792 (0.207933) valid loss(err) 0.508494901937 (0.277938)\n",
      "train loss(err) 0.437402252734 (0.206681) valid loss(err) 0.508494901937 (0.277938)\n",
      "train loss(err) 0.437126701631 (0.206628) valid loss(err) 0.508494901937 (0.277938)\n",
      "train loss(err) 0.434807921376 (0.205361) valid loss(err) 0.508494901937 (0.277938)\n",
      "train loss(err) 0.435892698009 (0.206041) valid loss(err) 0.508494901937 (0.277938)\n",
      "train loss(err) 0.434088700092 (0.205216) valid loss(err) 0.50979869694 (0.280735)\n",
      "train loss(err) 0.433532381272 (0.204825) valid loss(err) 0.50979869694 (0.280735)\n",
      "train loss(err) 0.432753412958 (0.204378) valid loss(err) 0.50979869694 (0.280735)\n",
      "train loss(err) 0.4313061162 (0.203571) valid loss(err) 0.50979869694 (0.280735)\n",
      "train loss(err) 0.431560904341 (0.204003) valid loss(err) 0.50979869694 (0.280735)\n",
      "train loss(err) 0.430831317282 (0.203642) valid loss(err) 0.505365714229 (0.279721)\n",
      "train loss(err) 0.430786321311 (0.203648) valid loss(err) 0.505365714229 (0.279721)\n",
      "train loss(err) 0.429024148487 (0.202599) valid loss(err) 0.505365714229 (0.279721)\n",
      "train loss(err) 0.428418085443 (0.202454) valid loss(err) 0.505365714229 (0.279721)\n",
      "train loss(err) 0.427606319913 (0.202099) valid loss(err) 0.505365714229 (0.279721)\n",
      "train loss(err) 0.427022839655 (0.201654) valid loss(err) 0.509271620161 (0.284363)\n",
      "train loss(err) 0.426579050516 (0.201239) valid loss(err) 0.509271620161 (0.284363)\n",
      "train loss(err) 0.426961868682 (0.201699) valid loss(err) 0.509271620161 (0.284363)\n",
      "train loss(err) 0.425577035822 (0.200646) valid loss(err) 0.509271620161 (0.284363)\n",
      "train loss(err) 0.424367214634 (0.200277) valid loss(err) 0.509271620161 (0.284363)\n",
      "train loss(err) 0.423567027402 (0.199522) valid loss(err) 0.505084802314 (0.280662)\n",
      "train loss(err) 0.422892232723 (0.199254) valid loss(err) 0.505084802314 (0.280662)\n",
      "train loss(err) 0.422016781195 (0.198226) valid loss(err) 0.505084802314 (0.280662)\n",
      "train loss(err) 0.422365293309 (0.19863) valid loss(err) 0.505084802314 (0.280662)\n",
      "train loss(err) 0.421943764851 (0.198299) valid loss(err) 0.505084802314 (0.280662)\n",
      "train loss(err) 0.421778506133 (0.197963) valid loss(err) 0.501682858893 (0.278821)\n",
      "train loss(err) 0.420936534068 (0.19761) valid loss(err) 0.501682858893 (0.278821)\n",
      "train loss(err) 0.42064534777 (0.197339) valid loss(err) 0.501682858893 (0.278821)\n",
      "train loss(err) 0.420143585729 (0.197236) valid loss(err) 0.501682858893 (0.278821)\n",
      "train loss(err) 0.420937427507 (0.197928) valid loss(err) 0.501682858893 (0.278821)\n",
      "train loss(err) 0.419680139526 (0.196923) valid loss(err) 0.503670216649 (0.281974)\n",
      "train loss(err) 0.418370323959 (0.195688) valid loss(err) 0.503670216649 (0.281974)\n",
      "train loss(err) 0.417674167954 (0.195496) valid loss(err) 0.503670216649 (0.281974)\n",
      "train loss(err) 0.418067425367 (0.195668) valid loss(err) 0.503670216649 (0.281974)\n",
      "train loss(err) 0.418348747438 (0.195764) valid loss(err) 0.503670216649 (0.281974)\n",
      "train loss(err) 0.417762228879 (0.195726) valid loss(err) 0.499235665766 (0.280197)\n",
      "train loss(err) 0.416456590829 (0.194623) valid loss(err) 0.499235665766 (0.280197)\n",
      "train loss(err) 0.416226884025 (0.194436) valid loss(err) 0.499235665766 (0.280197)\n",
      "train loss(err) 0.41628950959 (0.194703) valid loss(err) 0.499235665766 (0.280197)\n",
      "train loss(err) 0.415749791074 (0.194139) valid loss(err) 0.499235665766 (0.280197)\n",
      "train loss(err) 0.414228927731 (0.19293) valid loss(err) 0.506983779702 (0.285076)\n",
      "train loss(err) 0.415190783878 (0.193817) valid loss(err) 0.506983779702 (0.285076)\n",
      "train loss(err) 0.41543218963 (0.193931) valid loss(err) 0.506983779702 (0.285076)\n",
      "train loss(err) 0.413637550199 (0.192613) valid loss(err) 0.506983779702 (0.285076)\n",
      "train loss(err) 0.412938298887 (0.192231) valid loss(err) 0.506983779702 (0.285076)\n",
      "train loss(err) 0.414336512704 (0.193339) valid loss(err) 0.498448228231 (0.278989)\n",
      "train loss(err) 0.412880084783 (0.19212) valid loss(err) 0.498448228231 (0.278989)\n",
      "train loss(err) 0.413672487808 (0.192814) valid loss(err) 0.498448228231 (0.278989)\n",
      "train loss(err) 0.411575349607 (0.191222) valid loss(err) 0.498448228231 (0.278989)\n",
      "train loss(err) 0.412310443128 (0.19151) valid loss(err) 0.498448228231 (0.278989)\n"
     ]
    }
   ],
   "source": [
    "def train_model(X, y):\n",
    "    \n",
    "    train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size = 10000)\n",
    "    \n",
    "    ss_X = StandardScaler().fit(train_X)\n",
    "    ss_y = StandardScaler().fit(train_y)\n",
    "    scaled_train_X, scaled_valid_X = ss_X.transform(train_X), ss_X.transform(valid_X)\n",
    "    scaled_train_y, scaled_valid_y = ss_y.transform(train_y), ss_y.transform(valid_y)\n",
    "    \n",
    "    exp = theanets.Experiment(theanets.Regressor, layers = (4096, (200, \"tanh\"), 100))\n",
    "    for train, valid in exp.itertrain(train_set = (scaled_train_X, scaled_train_y), \n",
    "                                  valid_set = (scaled_valid_X, scaled_valid_y), \n",
    "                                  optimize = \"sgd\", learning_rate = 0.005, validate_every = 5,\n",
    "                                  hidden_l1 = 0.01, weight_l2 = 1e-4):\n",
    "        print 'train loss(err)', train['loss'], \"(%g)\" % train[\"err\"], 'valid loss(err)', valid['loss'], \"(%g)\" % valid['err']\n",
    "    return ss_X, ss_y, exp.network\n",
    "\n",
    "ss_X, ss_y, model = train_model(X_notruck, y_notruck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_by_model(xscaler, yscaler, model, X):\n",
    "    yhat = yscaler.inverse_transform(model.predict(xscaler.transform(X)))\n",
    "    return pairwise_distances_argmin(yhat, label_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airplane</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>airplane</th>\n",
       "      <td>5431</td>\n",
       "      <td>58</td>\n",
       "      <td>113</td>\n",
       "      <td>31</td>\n",
       "      <td>48</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>automobile</th>\n",
       "      <td>77</td>\n",
       "      <td>5795</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bird</th>\n",
       "      <td>153</td>\n",
       "      <td>7</td>\n",
       "      <td>4907</td>\n",
       "      <td>336</td>\n",
       "      <td>270</td>\n",
       "      <td>104</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>310</td>\n",
       "      <td>4440</td>\n",
       "      <td>219</td>\n",
       "      <td>672</td>\n",
       "      <td>175</td>\n",
       "      <td>104</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deer</th>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>283</td>\n",
       "      <td>204</td>\n",
       "      <td>5143</td>\n",
       "      <td>96</td>\n",
       "      <td>102</td>\n",
       "      <td>97</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>640</td>\n",
       "      <td>152</td>\n",
       "      <td>4852</td>\n",
       "      <td>50</td>\n",
       "      <td>101</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frog</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>154</td>\n",
       "      <td>233</td>\n",
       "      <td>168</td>\n",
       "      <td>56</td>\n",
       "      <td>5335</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horse</th>\n",
       "      <td>43</td>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>244</td>\n",
       "      <td>253</td>\n",
       "      <td>200</td>\n",
       "      <td>18</td>\n",
       "      <td>5128</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ship</th>\n",
       "      <td>186</td>\n",
       "      <td>65</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>5666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            airplane  automobile  bird   cat  deer   dog  frog  horse  ship\n",
       "airplane        5431          58   113    31    48    14    24     32   249\n",
       "automobile        77        5795     8    33     8     7     7     16    49\n",
       "bird             153           7  4907   336   270   104   150     50    23\n",
       "cat               41           9   310  4440   219   672   175    104    30\n",
       "deer              52           2   283   204  5143    96   102     97    21\n",
       "dog                9           1   187   640   152  4852    50    101     8\n",
       "frog              25           3   154   233   168    56  5335     22     4\n",
       "horse             43           9    90   244   253   200    18   5128    15\n",
       "ship             186          65    23    27     8    10     3     12  5666"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for images already seen\n",
    "yhat_notruck = predict_by_model(ss_X, ss_y, model, X_notruck)\n",
    "NOTRUCK_LABELS = [l for l in LABELS if l != \"truck\"]\n",
    "cm = pd.DataFrame(confusion_matrix(label_notruck, yhat_notruck), \n",
    "                  index = NOTRUCK_LABELS, columns=NOTRUCK_LABELS)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'automobile': 3746, 'airplane': 1115, 'ship': 553, 'horse': 221, 'cat': 185, 'bird': 66, 'deer': 53, 'dog': 42, 'frog': 19})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for unseen (truck) images - how are they map to the text\n",
    "yhat_truck = predict_by_model(ss_X, ss_y, model, X_truck)\n",
    "Counter(LABELS[yhat_truck])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** we see that even we don't see truck images before, most of them will be mapped to the word \"automobile\". But unfortunatelly none of the new images are really mapped to the word \"truck\" - obviously the mapping does a better job for interpolation than for extrapolation. For example, the arithmetic relation between the words \"truck\" and \"automobile\" are NOT captured by the mapping from images to words - because the image vectors themselves don't have similiar arithmetic relations as in word2vec. This could be caused by the lack of enough words for images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
