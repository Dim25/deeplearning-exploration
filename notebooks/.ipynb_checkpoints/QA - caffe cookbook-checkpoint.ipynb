{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Recipes of Caffe\n",
    "\n",
    "In spite of its popularity, the documentation of Caffe is not quite centeralized. This notebook serves as a summary of common use cases that we have practiced with Caffe. The knowledge is not gauranteed to be accurate, and may change in the future, as writing the notebook itself is a learning experience for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: How to install Caffe on Ubuntu (with pycaffe) ?\n",
    "***A***: see [installation guide](http://caffe.berkeleyvision.org/installation.html) and our [cheatsheet](https://github.com/dolaameng/deeplearning-exploration/blob/master/installation.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: How is Caffe package organized ?\n",
    "***A: *** If you follow the installation guide above, you will get an caffe root folder somewhere on your disk (e.g., ~/opt/caffe). There are several sub folders inside, with different functionalities.\n",
    "### 1. subfolders of source code\n",
    "- **src**: source code for caffe scaffold\n",
    "- **include**: header files\n",
    "- **tools**: source codes for main utitilies\n",
    "- **scripts**: auxiliary tools such as upload/download model to gist\n",
    "- **cmake**: configuration for compilation of source code\n",
    "- **matlab**: source for +caffe\n",
    "- **python**: source for pycaffe\n",
    "\n",
    "### 2. subfolders of documentation\n",
    "- **docs**: main documentation, including a tutorial from official website\n",
    "- **examples**: live code on how to use caffe, including ipython notebooks\n",
    "- **data**: scripts to download procesed data that are used across different tutorial examples\n",
    "\n",
    "### 3. subfolders of main functionality\n",
    "- **build/tool**: the main access point for caffe functionality, including the `caffe` command, and tools for common tasks such as `finetune_net`, `compute_image_mean`, `convert_imageset` and `device_query`\n",
    "- **models**: the default repository for caffe zoo models\n",
    "\n",
    "The recommended use pattern is to set CAFFE_ROOT as an env variable or constant path, and refer to the relatively fixed subfolders in your code.\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: What are common usages for Caffe?\n",
    "- train a model with your own data from scratch\n",
    "- load a model with existing structure and weights into an programming langauge (python, matlab, c++)\n",
    "    - modify the structure and fine-tune existing weights\n",
    "    - fine-tune weights with new data, or fine-tune selected layers\n",
    "    - evaluate model with new data to extract outputs of different layers for other usage\n",
    "    - evaluate model on new images to make classification\n",
    "    \n",
    "Generally those tasks can be done either via \"commandline interface\" or a programming API (e.g., python, matlab). The choice depends on the applications.\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: How to find and download a zoo model in Caffe?\n",
    "**A**: The way people define and contribute their models are more by convention instead of by rules. Most caffe models can be found in the [model-zoo page](https://github.com/BVLC/caffe/wiki/Model-Zoo). For each contributed model, its minimum usually includes,\n",
    "- a readme.md file to describe the model, data, and its usage\n",
    "- to repeat the training: \n",
    "    - a `train_val.prototxt` or equivalent to define the structure/parameters of net\n",
    "    - a `solver.prototxt` to define the optimization algorithm\n",
    "    - original dataset for the model, with processing scripts if necessary\n",
    "- to evaluate the model\n",
    "    - a `*.caffemodel` containing pretrained weights\n",
    "    - optionally a `deploy.prototxt` specially for classication. If it is not given, most of time it is the same with training structure defined in `train_val.prototxt`, or with minor changes \n",
    "    - optionally other extra file to interpret the output of the model, e.g., the meaning of labels. These may have been included in the original data\n",
    "    \n",
    "You should download those files for a model and put in a specific subfolder (named after the model) in `CAFFE_ROOT/models`. Some models may be more complicated to get, e.g., [fast-rcnn](https://github.com/rbgirshick/fast-rcnn)\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: What makes a Caffe model?\n",
    "**A**: Different aspects of a Caffe model include,\n",
    "- ***Statically***, a caffe **Net** model is a set of **Layers**. Layers can be imagined as \"nodes\"\" in a DAG graph, and the connections between nodes are the \"flow of data\", which are defined as **Blobs** in Caffe. Each layer in the model has a \"type\", and optionally its connected \"input\" and \"output\", and \"weights\" parameters. \n",
    "The static model is defined as *** model prototype (.prototxt)*** file (the txt version of google protobuf). Since the structure and flow (nodes and connections) of the model depends on how it is used (e.g., training, evaluation), there might be multiple model prototype files, e.g., \"train_val.prototxt\" and \"deploy.prototxt\".\n",
    "- ***Dynamically***, there are two computation flows through the model - `forward` and `backward`. Both can happen through the whole network or only across several layers. Most of time, the backward computation requires the model to cache the forward results, which is expensive for a forward-only case. So the caffe model usually needs to explicitly specify the ***force_backward*** parameter to be true in model prototype - equivallent to making the DAG graph of net *bidirectional*.\n",
    "- ***Computationally***, you need a solver prototype (usually in ***solver.prototxt***) or a pretained weight file (***.caffemodel***) to put the model in use.  \n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: How to understand a model's *train_val.prototxt* or *deploy.prototxt* files?\n",
    "**A:**: Both are text version of prototypes based on `caffe.proto` definition. They are used to define the structure/parameters of a net model. The first is usually used for training phase (with a validation) and the second is for evaluation of model with new data.\n",
    "\n",
    "The prototxt file itself can be viewed as a set of objects. An object can be a key:value pair with \":\" as the delimiter, or an object message as defined in `caffe.proto`. The \",\" or \";\" are not usually used to delimit entries in the file. The minimum scaffold of a model prototype file should include\n",
    "- ***train_val.prototxt***\n",
    "```\n",
    "name: \"NameOfModel\"\n",
    "// start with data layer\n",
    "layer {\n",
    "    name: \"data\"\n",
    "    type: \"ImageData\"\n",
    "    ...\n",
    "}\n",
    "...\n",
    "layer {\n",
    "    name: \"accuracy\"\n",
    "    type: \"Accuracy\"\n",
    "    ...\n",
    "}\n",
    "layer {\n",
    "    name: \"loss\"\n",
    "    type: \"SoftmaxWithLoss\"\n",
    "    ...\n",
    "}\n",
    "```\n",
    "- ***deploy.prototxt***\n",
    "```\n",
    "name: \"NameOfModel\"\n",
    "input: \"data\"\n",
    "//input_dim DEPRECATED, use input_shape as recommended\n",
    "//however you can still find them in most of existing models\n",
    "input_dim: batch_size \n",
    "input_dim: nchannels\n",
    "input_dim: img_width\n",
    "input_dim: img_height\n",
    "// there is no data layer in deploy.prototxt\n",
    "...\n",
    "layer {\n",
    "    name: \"prob\"\n",
    "    type: \"Softmax\"\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "The intermediate layers in both files should be defined the same. Different types of layers can be found in [Caffe layer tutorial](http://caffe.berkeleyvision.org/tutorial/layers.html) and the data layer definition can be found in [Caffe data layer tutorial](http://caffe.berkeleyvision.org/tutorial/data.html)\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: What is the difference between *train_val.prototxt* and *deploy.prototxt*? Are there any other conventional prototxt for model structure?\n",
    "**A:** The main difference between `train_val.prototxt` and `deploy.prototxt` include,\n",
    "- `train_val.prototxt` specify model data with a ***data layer***, whereas `deploy.prototxt` specify data with ***NetParameter*** including *input*, *input_shape* (or four *input_dim* in old version)\n",
    "- `train_val.prototxt` usually finishes with definition of a ***loss layer*** and optionally ***accuracy layer***, whereas `deploy.prototxt` usually finishes with a ***prob layer*** for class predictions\n",
    "- `train_val.prototxt` is mainly used with a `solver.prototxt` to train a model, whereas `deploy.prototxt` is mainly used for model evaluation on new images\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: How to understand a model's *solver.prototxt* file?\n",
    "**A: ** The main purpose of the `solver.prototxt` is to (1) train the caffe model (2) save/restore model weights in `*.caffemodel` and (3) save/restore solver status in `*.solverstate`\n",
    "## TODO\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: How to take a pre-trained model and fine-tune to new tasks?\n",
    "## A: [TODO](https://docs.google.com/presentation/d/1UeKXVgRvvxg9OUdh_UiC5G71UMscNPlvArsWER41PsU/edit?pli=1#slide=id.gc2fcdcce7_216_376)\n",
    "## fine tune last several layers\n",
    "\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: Where to find caffe protobuf definition file?\n",
    "**A: ** It is located in `CAFFE_ROOT/src/caffe/proto/caffe.proto`, or online version from [github](https://github.com/BVLC/caffe/blob/master/src/caffe/proto/caffe.proto)\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: How to parse a google prototxt file via programming api?\n",
    "## Q: How to load a caffe weight file *.caffemodel\n",
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Caffe site](http://caffe.berkeleyvision.org/)\n",
    "- [google/deepdream](https://github.com/google/deepdream)\n",
    "- [Stanford CS class CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/)\n",
    "- [Code Example - Tune Model Parameters](http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/net_surgery.ipynb)\n",
    "- [Code Example - Classifying New Images with Existing Model](http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/00-classification.ipynb)\n",
    "- [Code Example - Train a Model via pycaffe](http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/01-learning-lenet.ipynb)\n",
    "- [Code Example - build a caffe model on iris](http://www.stackoverflow.dluat.com/questions/31385427/how-to-train-a-caffe-model)\n",
    "- [Caffe notes in Chinese](http://dirlt.com/caffe.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
