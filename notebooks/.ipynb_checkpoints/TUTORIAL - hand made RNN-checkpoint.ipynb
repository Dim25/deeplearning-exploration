{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [char-nn by Karpathy](https://github.com/karpathy/char-rnn)\n",
    "- [RNN on WILDML](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/) and [code](https://github.com/dennybritz/rnn-tutorial-rnnlm)\n",
    "- implement simple RNN (nor LSTM nor GRU) with theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980M (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano import shared, function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.config.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate some simple artificial data to better understand the mechanism of RNN\n",
    "- Using [The Four Millions](http://www.gutenberg.org/cache/epub/2776/pg2776.txt) from gutenberg project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 316457\n"
     ]
    }
   ],
   "source": [
    "texts = open(\"../data/4millions.txt\").read()\n",
    "charset = set(texts)\n",
    "ind2char = dict(enumerate(charset))\n",
    "char2ind = dict(map(reversed, ind2char.items()))\n",
    "data = map(char2ind.get, texts)\n",
    "\n",
    "print len(charset), len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## char RNN with explicit loop\n",
    "- fixed window lenght\n",
    "- Because the network is not really deep (max seq len is 5), so using simple weights initialization\n",
    "- Use traditional `tanh` for linearity\n",
    "- simple derivative clip between -5, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## variable dimensions\n",
    "L = 25 # window length\n",
    "D = len(charset) # word dimension\n",
    "H = 100 # hidden dimension\n",
    "lr = 0.01 # learning rate\n",
    "lmbda = 0.01\n",
    "###############################################################\n",
    "\n",
    "x = T.ivector(name = \"x\") # seq of word hashs\n",
    "y = T.ivector(name = \"y\") # seq of next-word hashs\n",
    "\n",
    "################################################################\n",
    "\n",
    "Wxh = shared(np.random.randn(D, H) / np.sqrt(D), name = \"Wxh\")\n",
    "Whh = shared(np.random.randn(H, H) / np.sqrt(H), name = \"Whh\")\n",
    "bh = shared(np.zeros(H), name = \"bh\")\n",
    "Why = shared(np.random.randn(H, D) / np.sqrt(H), name = \"Why\")\n",
    "by = shared(np.zeros(D), name = \"by\")\n",
    "\n",
    "hs = [None] * (L+1)\n",
    "probs = [None] * L\n",
    "errors = [None] * L\n",
    "\n",
    "hs[-1] = shared(np.zeros(H), name = \"h_init\")\n",
    "for i in xrange(L):\n",
    "    hs[i] = T.tanh(Wxh[x[i], :] + Whh.dot(hs[i-1]) + bh)\n",
    "    probs[i] = T.nnet.softmax(hs[i].dot(Why) + by).flatten()\n",
    "    errors[i] = -T.log(probs[i][y[i]])\n",
    "\n",
    "data_loss = sum(errors)\n",
    "reg_loss = (Wxh * Wxh).sum() + (Whh * Whh).sum() + (Why * Why).sum()\n",
    "loss = data_loss + lmbda * reg_loss\n",
    "\n",
    "dWxh = T.clip(T.grad(loss, Wxh), -5, 5)\n",
    "dWhh = T.clip(T.grad(loss, Whh), -5, 5)\n",
    "dbh = T.clip(T.grad(loss, bh), -5, 5)\n",
    "dWhy = T.clip(T.grad(loss, Why), -5, 5)\n",
    "dby = T.clip(T.grad(loss, by), -5, 5)\n",
    "\n",
    "###################################################################\n",
    "train_on_seq = function(inputs = [x, y], \n",
    "                        outputs = [loss], \n",
    "                        updates = [ (Wxh, Wxh - lr * dWxh)\n",
    "                                  , (Whh, Whh - lr * dWhh)\n",
    "                                  , (bh, bh - lr * dbh)\n",
    "                                  , (Why, Why - lr * dWhy)\n",
    "                                  , (by, by - lr * dby)])\n",
    "\n",
    "predict_prob = function(inputs = [x], \n",
    "                  outputs = probs[-1])\n",
    "\n",
    "predict = function(inputs = [x], \n",
    "                  outputs = probs[-1].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array(115.85033294086065)], 114.62418696676431)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test initialization\n",
    "train_on_seq(x = [0] * L, y = [0] * L), -np.log(1./D) * L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=1, iseq=38, ichar=0, loss=97.5848\n",
      "iteration=2, iseq=77, ichar=0, loss=88.0225\n",
      "iteration=3, iseq=116, ichar=0, loss=82.8493\n",
      "iteration=4, iseq=155, ichar=0, loss=78.878\n",
      "iteration=5, iseq=194, ichar=0, loss=75.9255\n",
      "iteration=6, iseq=233, ichar=0, loss=73.195\n",
      "iteration=7, iseq=272, ichar=0, loss=71.2562\n",
      "iteration=8, iseq=311, ichar=0, loss=68.7904\n",
      "iteration=9, iseq=350, ichar=0, loss=67.1693\n",
      "iteration=10, iseq=389, ichar=0, loss=65.6779\n"
     ]
    }
   ],
   "source": [
    "## overfit a small dataset\n",
    "ichar = 0\n",
    "iteration = 0\n",
    "iseq = 0\n",
    "total_loss = 0\n",
    "N = 1000\n",
    "for iseq in xrange(10*N/L):\n",
    "    xval = data[ichar:ichar+L]\n",
    "    yval = data[ichar+1:ichar+1+L]\n",
    "    loss = train_on_seq(xval, yval)[0]\n",
    "    total_loss += loss\n",
    "    ichar += L\n",
    "    if ichar+1+L >= N: \n",
    "        ichar = 0\n",
    "        iteration += 1\n",
    "        print \"iteration=%i, iseq=%i, ichar=%i, loss=%g\" % (iteration, iseq, ichar, total_loss / (N*1. / L))\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=1, iseq=12657, ichar=0, loss=60.5135\n",
      "iteration=2, iseq=25315, ichar=0, loss=60.5437\n",
      "iteration=3, iseq=37973, ichar=0, loss=60.5185\n",
      "iteration=4, iseq=50631, ichar=0, loss=60.4995\n",
      "iteration=5, iseq=63289, ichar=0, loss=60.4887\n",
      "iteration=6, iseq=75947, ichar=0, loss=60.4934\n",
      "iteration=7, iseq=88605, ichar=0, loss=60.5534\n",
      "iteration=8, iseq=101263, ichar=0, loss=60.4818\n",
      "iteration=9, iseq=113921, ichar=0, loss=60.4696\n",
      "iteration=10, iseq=126579, ichar=0, loss=60.4553\n"
     ]
    }
   ],
   "source": [
    "ichar = 0\n",
    "iteration = 0\n",
    "iseq = 0\n",
    "total_loss = 0\n",
    "N = len(data)\n",
    "for iseq in xrange(10*N/L):\n",
    "    xval = data[ichar:ichar+L]\n",
    "    yval = data[ichar+1:ichar+1+L]\n",
    "    loss = train_on_seq(xval, yval)[0]\n",
    "    total_loss += loss\n",
    "    ichar += L\n",
    "    if ichar+1+L >= N: \n",
    "        ichar = 0\n",
    "        iteration += 1\n",
    "        print \"iteration=%i, iseq=%i, ichar=%i, loss=%g\" % (iteration, iseq, ichar, total_loss / (N*1. / L))\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word Rnn with theano scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
