{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seq prediction with variable length inputs\n",
    "- For seq2seq modelling, most of time the sequences of variable lengths will be padded as it doesn't affect the objective functions in most cases.\n",
    "- Another work-around is to train the seqences one by one, or in batch organized based on same sequence lengths\n",
    "- Replicate Keras [`addition_rnn.py`](https://github.com/fchollet/keras/blob/master/examples/addition_rnn.py) example, experimenting with training on variable len seqences\n",
    "- More discussions can be found [here](https://github.com/fchollet/keras/issues/40) and [here](https://github.com/fchollet/keras/issues/424)\n",
    "- The solution discussed in the article is only applicable to \"theano\" backend, but not to \"tensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import models, layers, optimizers, objectives, metrics\n",
    "from keras.preprocessing import sequence, text\n",
    "from itertools import groupby, cycle, chain, islice\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"epsilon\": 1e-07, \"floatx\": \"float32\", \"backend\": \"theano\"}\r\n"
     ]
    }
   ],
   "source": [
    "!cat /root/.keras/keras.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode/decode of sequences\n",
    "- support both fixed length encoding with a default padding and variable length encoding\n",
    "- for RNN training, it is ok to use sequences of different lengths as input, but the lengths of output sequence still need to be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "charset = \"0123456789+ \"\n",
    "int2char = dict(enumerate(charset))\n",
    "char2int = dict((c, i) for i,c in enumerate(charset))\n",
    "def encode(expr, seqlen = None, padchar = \" \"):\n",
    "    \"\"\"set seqlen to enforce a fixed-length encoding of a sequence with pad\n",
    "    \"\"\"\n",
    "    seqlen = seqlen or len(expr)\n",
    "    \n",
    "    vec = np.zeros((len(expr), len(charset)))\n",
    "    vec[range(len(expr)), map(char2int.get, expr)] = 1\n",
    "    if seqlen > len(expr):\n",
    "        pad_vec = np.zeros( (1, len(charset)) )\n",
    "        pad_vec[0, char2int.get(padchar)] = 1\n",
    "        vec = np.r_[vec, np.repeat(pad_vec, seqlen - len(expr), axis = 0)]\n",
    "    return vec\n",
    "def decode(vec):\n",
    "    expr = \"\".join([int2char.get(r.argmax()) for r in vec])\n",
    "    return expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of encoding/decoding '311+3'\n",
      "Example of encoding/decoding with padding '314  '\n"
     ]
    }
   ],
   "source": [
    "print(\"Example of encoding/decoding '%s'\" % decode(encode(\"311+3\")))\n",
    "print(\"Example of encoding/decoding with padding '%s'\" % decode(encode(\"314\", seqlen=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## genereate training and validation data\n",
    "- training data:\n",
    "    - inputs are sequences of variable lengths\n",
    "    - outputs are sequences of fixed lengths\n",
    "- validation data:\n",
    "    - both inputs and outputs are sequences of fixed lengths, for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(ndigits, nquestions):\n",
    "    seen = set()\n",
    "    questions, answers = [], []\n",
    "    nextn = lambda : int(\"\".join(np.random.choice(np.array(list(\"0123456789\")), ndigits, replace =True)))\n",
    "    while len(questions) < nquestions:\n",
    "        a, b = nextn(), nextn()\n",
    "        key = tuple(sorted([a, b]))\n",
    "        if key in seen: continue\n",
    "        seen.add(key)\n",
    "        expr1 = \"%i+%i\" % (a, b)\n",
    "        expr2 = \"%i+%i\" % (b, a)\n",
    "        ans = str(a+b)\n",
    "        questions.append(expr1)\n",
    "        answers.append(ans)\n",
    "        questions.append(expr2)\n",
    "        answers.append(ans)\n",
    "    questions, answers = shuffle(questions, answers)\n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mix digits 2 and 3 for training\n",
    "\n",
    "***It is a harder problem now because part of task is to predict on 3 digits based on training with 2 digits***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 524 ms, sys: 0 ns, total: 524 ms\n",
      "Wall time: 519 ms\n",
      "CPU times: user 564 ms, sys: 0 ns, total: 564 ms\n",
      "Wall time: 555 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ndigits = 3\n",
    "%time questions2, answers2 = generate_data(3, 40000)\n",
    "%time questions3, answers3 = generate_data(2, 10000)\n",
    "train_questions = questions2 + questions3\n",
    "train_answers = answers2 + answers3\n",
    "\n",
    "## train_X is a list of matrices with variable shapes\n",
    "## train_y is a list of matrices with fixed shapes\n",
    "train_X = [encode(q) for q in train_questions] ## encoding question seqs with variable len\n",
    "train_y = [encode(a, seqlen=ndigits+1) for a in train_answers] ## encoding answer seqs with fixed len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({7: 32470, 5: 9124, 6: 6444, 4: 1856, 3: 106})\n",
      "Counter({4: 50000})\n"
     ]
    }
   ],
   "source": [
    "## see the length distributions of train_questions\n",
    "\n",
    "from collections import Counter\n",
    "len_counter = Counter(map(lambda m: m.shape[0], train_X))\n",
    "print(len_counter)\n",
    "len_counter = Counter(map(lambda m: m.shape[0], train_y))\n",
    "print(len_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "***In this example, longer sequence will just dominate. So I am just showing how this can be done practically, but it doesn't suggest that this is necessarily the way of training a good model - There is a reason why padding is so popular.***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 68 ms, sys: 0 ns, total: 68 ms\n",
      "Wall time: 65.8 ms\n",
      "(5000, 7, 12) (5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "## generate new data for validation\n",
    "ndigits = 3\n",
    "%time valid_questions, valid_answers = generate_data(3, 5000)\n",
    "\n",
    "## Both valid_X and valid_y are encoded with padding, for simplicity\n",
    "valid_X = np.array([encode(q, seqlen=ndigits*2+1) for q in valid_questions]) \n",
    "valid_y = np.array([encode(a, seqlen=ndigits+1) for a in valid_answers])\n",
    "print(valid_X.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    n_hidden_layers = 1\n",
    "    input_dim = len(charset)\n",
    "    hidden_dim = 128\n",
    "    output_dim = len(charset)\n",
    "    output_seq_len = ndigits + 1\n",
    "\n",
    "    model = models.Sequential()\n",
    "    ## indicate accepting variable length sequences by not fixing the first input dim\n",
    "    model.add(layers.LSTM(hidden_dim, input_shape = (None, input_dim), name = \"input_lstm\"))\n",
    "    model.add(layers.RepeatVector(output_seq_len, name = \"output_seq\"))\n",
    "    for i in xrange(n_hidden_layers):\n",
    "        model.add(layers.LSTM(hidden_dim, return_sequences = True, name = \"hidden_seq_rnn%i\" % i))\n",
    "    model.add(layers.TimeDistributed(layers.Dense(output_dim), name = \"output_vec\"))\n",
    "    model.add(layers.Activation(\"softmax\", name = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layername: input_lstm \tInputs: (None, None, 12) \tOutputs: (None, 128)\n",
      "Layername: output_seq \tInputs: (None, 128) \tOutputs: (None, 4, 128)\n",
      "Layername: hidden_seq_rnn0 \tInputs: (None, 4, 128) \tOutputs: (None, 4, 128)\n",
      "Layername: output_vec \tInputs: (None, 4, 128) \tOutputs: (None, 4, 12)\n",
      "Layername: softmax \tInputs: (None, 4, 12) \tOutputs: (None, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "def inspect_model(model):\n",
    "    for layer in model.layers:\n",
    "        print(\"Layername:\", layer.name, \n",
    "              \"\\tInputs:\", layer.input_shape, \n",
    "              \"\\tOutputs:\", layer.output_shape)\n",
    "        \n",
    "inspect_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1: use generator to group training data of different lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import groupby, cycle, chain, islice\n",
    "def batch_data_generator(inputs_list, outputs_list, batch_size = 32):\n",
    "    \"\"\"\n",
    "    Group inputs and outputs by input sizes\n",
    "    Generate batches from same size group, with padding if necessary\n",
    "    \"\"\"\n",
    "    assert (len(inputs_list) == len(outputs_list))\n",
    "    index = range(len(inputs_list))\n",
    "    keyfun = lambda i: inputs_list[i].shape[0] ## input shape as key\n",
    "    groups_by_sz = groupby(sorted(index, key = keyfun), key = keyfun)\n",
    "    \n",
    "    grp_indices = []\n",
    "    for sz, subindex in groups_by_sz:\n",
    "        ## pad subindex to make it a multiple of batch_size\n",
    "        subindex = list(subindex)\n",
    "        r = len(subindex) % batch_size\n",
    "        padded_sz = len(subindex) if r == 0 else len(subindex) + (batch_size-r)\n",
    "        subindex = islice(cycle(subindex), 0, padded_sz)\n",
    "        grp_indices.append(subindex)\n",
    "    looped_index = cycle(chain(*grp_indices))\n",
    "    \n",
    "    while True:\n",
    "        batch_index = []\n",
    "        for i in xrange(batch_size):\n",
    "            i = looped_index.next()\n",
    "            batch_index.append(i)\n",
    "        batch_X = np.array([inputs_list[i] for i in batch_index])\n",
    "        batch_y = np.array([outputs_list[i] for i in batch_index])\n",
    "        yield (batch_X, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19+84 = 103 \n",
      "92+73 = 165 \n",
      "65+67 = 132 \n",
      "68+48 = 116 \n",
      "================================================================\n",
      "27+33 = 60  \n",
      "20+48 = 68  \n",
      "61+79 = 140 \n",
      "24+98 = 122 \n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "# how it works\n",
    "for batch_x, batch_y in islice(batch_data_generator(train_X, train_y, batch_size=4), 1000, 1002):\n",
    "    exprs = [decode(x) for x in batch_x]\n",
    "    answs = [decode(y) for y in batch_y]\n",
    "    for expr, ans in zip(exprs, answs):\n",
    "        print(\"%s = %s\" % (expr, ans))\n",
    "    print (\"=\"*64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** finally, train the model in batch, with varational length sequences ***\n",
    "- training with groups of varitional lengths seem to have influnces on performance and convergence.\n",
    "- because of the differences of different length groups, the graidents jump more wildly during one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_generator = batch_data_generator(train_X, train_y, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "50016/50016 [==============================] - 28s - loss: 1.5508 - acc: 0.4384 - val_loss: 1.9717 - val_acc: 0.4310\n",
      "Epoch 2/20\n",
      "50016/50016 [==============================] - 28s - loss: 1.3062 - acc: 0.5248 - val_loss: 1.9081 - val_acc: 0.4888\n",
      "Epoch 3/20\n",
      "50016/50016 [==============================] - 28s - loss: 1.1235 - acc: 0.5947 - val_loss: 1.7373 - val_acc: 0.5808\n",
      "Epoch 4/20\n",
      "50016/50016 [==============================] - 25s - loss: 0.9020 - acc: 0.6783 - val_loss: 1.6347 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "50016/50016 [==============================] - 29s - loss: 0.5616 - acc: 0.8247 - val_loss: 1.7091 - val_acc: 0.7818\n",
      "Epoch 6/20\n",
      "50016/50016 [==============================] - 30s - loss: 0.3834 - acc: 0.8955 - val_loss: 1.7503 - val_acc: 0.8208\n",
      "Epoch 7/20\n",
      "50016/50016 [==============================] - 29s - loss: 0.2954 - acc: 0.9215 - val_loss: 1.8223 - val_acc: 0.8292\n",
      "Epoch 8/20\n",
      "50016/50016 [==============================] - 29s - loss: 0.2509 - acc: 0.9329 - val_loss: 1.8614 - val_acc: 0.8357\n",
      "Epoch 9/20\n",
      "50016/50016 [==============================] - 29s - loss: 0.2122 - acc: 0.9422 - val_loss: 1.8868 - val_acc: 0.8348\n",
      "Epoch 10/20\n",
      "50016/50016 [==============================] - 29s - loss: 0.1848 - acc: 0.9510 - val_loss: 1.8947 - val_acc: 0.8390\n",
      "Epoch 11/20\n",
      "50016/50016 [==============================] - 29s - loss: 0.1649 - acc: 0.9561 - val_loss: 1.8841 - val_acc: 0.8348\n",
      "Epoch 12/20\n",
      "50016/50016 [==============================] - 29s - loss: 0.1477 - acc: 0.9608 - val_loss: 1.8887 - val_acc: 0.8340\n",
      "Epoch 13/20\n",
      "50016/50016 [==============================] - 29s - loss: 0.1244 - acc: 0.9667 - val_loss: 1.8837 - val_acc: 0.8329\n",
      "Epoch 14/20\n",
      "50016/50016 [==============================] - 29s - loss: 0.1063 - acc: 0.9712 - val_loss: 1.9039 - val_acc: 0.8376\n",
      "Epoch 15/20\n",
      "50016/50016 [==============================] - 29s - loss: 0.0973 - acc: 0.9725 - val_loss: 1.9382 - val_acc: 0.8296\n",
      "Epoch 16/20\n",
      "50016/50016 [==============================] - 29s - loss: 0.0798 - acc: 0.9773 - val_loss: 1.9371 - val_acc: 0.8377\n",
      "Epoch 17/20\n",
      "50016/50016 [==============================] - 29s - loss: 0.0689 - acc: 0.9800 - val_loss: 1.9723 - val_acc: 0.8409\n",
      "Epoch 18/20\n",
      "50016/50016 [==============================] - 29s - loss: 0.0674 - acc: 0.9807 - val_loss: 1.9646 - val_acc: 0.8334\n",
      "Epoch 19/20\n",
      "50016/50016 [==============================] - 30s - loss: 0.0604 - acc: 0.9827 - val_loss: 1.9881 - val_acc: 0.8446\n",
      "Epoch 20/20\n",
      "50016/50016 [==============================] - 30s - loss: 0.0546 - acc: 0.9840 - val_loss: 2.0113 - val_acc: 0.8402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4e59fd9950>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, samples_per_epoch = (len(train_X) / batch_size+1) * batch_size, nb_epoch=20, \n",
    "                   validation_data = (valid_X, valid_y), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0113413022994995, 0.84019999999999995]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_X, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786+306 = 1092 -> 1092\n",
      "254+340 = 594  -> 694 \n",
      "80+309  = 389  -> 1486\n",
      "246+259 = 505  -> 505 \n",
      "964+178 = 1142 -> 1142\n",
      "830+956 = 1786 -> 1786\n",
      "995+65  = 1060 -> 1650\n",
      "682+461 = 1143 -> 1143\n",
      "763+752 = 1515 -> 1515\n",
      "477+974 = 1451 -> 1451\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(valid_X.shape[0], 10, replace=False)\n",
    "sampleX, sampley = valid_X[i, :], valid_y[i]\n",
    "sampleyhat = model.predict(sampleX)\n",
    "\n",
    "for x, y, yhat in zip(sampleX, sampley, sampleyhat):\n",
    "    print(decode(x), \"=\", decode(y), \"->\", decode(yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2: An alternative is to train the model - sequentially train on different sizes\n",
    "- in the previous solution, training got stuck somewhere after leaping between different groups\n",
    "- improvement by changing learning algorithm, restructuring network, adding more regularization, shuffle the batch from different groups?\n",
    "- we shuffle the different batches here - not much improvement in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## partition the training data by sizes\n",
    "def partition_data(inputs_list, outputs_list, batch_size = 32):\n",
    "    assert (len(inputs_list) == len(outputs_list))\n",
    "    index = range(len(inputs_list))\n",
    "    keyfun = lambda i: inputs_list[i].shape[0] ## input shape as key\n",
    "    groups_by_sz = groupby(sorted(index, key = keyfun), key = keyfun)\n",
    "    \n",
    "    index_groups = {}\n",
    "    for sz, subindex in groups_by_sz:\n",
    "        subindex = list(subindex)\n",
    "        if len(subindex) % batch_size == 0:\n",
    "            padded_sz = len(subindex) \n",
    "        else:\n",
    "            padded_sz = (len(subindex) / batch_size + 1) * batch_size\n",
    "        subindex = list(islice(cycle(subindex), 0, padded_sz))\n",
    "        for ibatch in xrange(padded_sz / batch_size):\n",
    "            index_groups[\"%i_%i\" % (sz, ibatch)] = subindex[ibatch*batch_size:(ibatch+1)*batch_size]\n",
    "    return index_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## chunks of batch index, within the same chunk, the input data shape are always the same\n",
    "train_index_groups = partition_data(train_X, train_y, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s     \n",
      "epoch 0 validation performance [1.9186408332824707, 0.42830000000000001]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 1 validation performance [1.9998241294860839, 0.43964999999999999]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 2 validation performance [1.9460379375457764, 0.4758]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 3 validation performance [1.9206396116256714, 0.59204999999999997]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 4 validation performance [1.8321751346588135, 0.66400000000000003]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 5 validation performance [1.7385511131286622, 0.79744999999999999]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 6 validation performance [1.8385612802505493, 0.79269999999999996]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 7 validation performance [1.8151056520462037, 0.83015000000000005]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 8 validation performance [1.8583248208999634, 0.82555000000000001]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 9 validation performance [1.8356214509010316, 0.82769999999999999]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 10 validation performance [1.8443672791481018, 0.84640000000000004]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 11 validation performance [1.895765985584259, 0.84465000000000001]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 12 validation performance [1.9419121088027953, 0.83884999999999998]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 13 validation performance [1.9480765412330627, 0.84609999999999996]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 14 validation performance [1.9495856570243835, 0.84635000000000005]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 15 validation performance [1.9553294983386993, 0.84830000000000005]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 16 validation performance [1.8966812218666076, 0.84740000000000004]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 17 validation performance [1.9769376670837402, 0.83789999999999998]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 18 validation performance [1.9710628666877748, 0.85009999999999997]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 19 validation performance [1.992828085231781, 0.84260000000000002]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 20 validation performance [2.0111081174373626, 0.84289999999999998]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 21 validation performance [1.9449517462730408, 0.85150000000000003]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 22 validation performance [2.0548765928268433, 0.82335000000000003]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 23 validation performance [1.9897982642173766, 0.84060000000000001]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 24 validation performance [2.0079802431106568, 0.84975000000000001]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 25 validation performance [2.0023834218025209, 0.85085]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 26 validation performance [1.969526531124115, 0.85194999999999999]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 27 validation performance [1.936216599559784, 0.85250000000000004]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 28 validation performance [1.9374705356597901, 0.85304999999999997]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 29 validation performance [2.0020545827865601, 0.8508]\n"
     ]
    }
   ],
   "source": [
    "## recreate model to reset, no simple way of doing it in keras YET\n",
    "## https://github.com/fchollet/keras/pull/1908\n",
    "model2 = create_model()\n",
    "\n",
    "nb_epoch = 30\n",
    "for epoch in xrange(nb_epoch):\n",
    "    for batch_index in shuffle(train_index_groups.values()):\n",
    "        batch_X = np.array([train_X[i] for i in batch_index])\n",
    "        batch_y = np.array([train_y[i] for i in batch_index])\n",
    "        model2.fit(batch_X, batch_y, nb_epoch=1, verbose = 0)\n",
    "    print(\"epoch %i\" % epoch, \"validation performance\", model2.evaluate(valid_X, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s     \n",
      "[2.0020545827865601, 0.8508]\n",
      "43+645  = 688  -> 989 \n",
      "649+621 = 1270 -> 1270\n",
      "959+803 = 1762 -> 1762\n",
      "965+392 = 1357 -> 1357\n",
      "630+148 = 778  -> 778 \n",
      "752+659 = 1411 -> 1411\n",
      "50+711  = 761  -> 76  \n",
      "546+633 = 1179 -> 1179\n",
      "478+185 = 663  -> 663 \n",
      "381+319 = 700  -> 700 \n"
     ]
    }
   ],
   "source": [
    "print(model2.evaluate(valid_X, valid_y))\n",
    "i = np.random.choice(valid_X.shape[0], 10, replace=False)\n",
    "sampleX, sampley = valid_X[i, :], valid_y[i]\n",
    "sampleyhat = model2.predict(sampleX)\n",
    "\n",
    "for x, y, yhat in zip(sampleX, sampley, sampleyhat):\n",
    "    print(decode(x), \"=\", decode(y), \"->\", decode(yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 3: Or, even to train the model group by group\n",
    "- but it is almost as the same as training on the dominating group in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s     \n",
      "epoch 19 training on size 3 validation performance [6.2249597793579099, 0.25509999999999999]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 19 training on size 4 validation performance [5.3433155868530271, 0.20699999999999999]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 19 training on size 5 validation performance [6.8431203826904294, 0.22245000000000001]\n",
      "5000/5000 [==============================] - 1s     \n",
      "epoch 19 training on size 6 validation performance [8.1787536987304694, 0.26390000000000002]\n",
      "5000/5000 [==============================] - 0s     \n",
      "epoch 19 training on size 7 validation performance [2.0483857035636901, 0.81310000000000004]\n"
     ]
    }
   ],
   "source": [
    "model3 = create_model()\n",
    "\n",
    "nb_epoch = 20\n",
    "\n",
    "for sz, (group_X, group_y) in train_data_groups.items():\n",
    "    model3.fit(group_X, group_y, nb_epoch=nb_epoch, verbose = 0)\n",
    "    print(\"epoch %i training on size %i\" % (epoch, sz), \"validation performance\", model3.evaluate(valid_X, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s     \n",
      "[2.0483857035636901, 0.81310000000000004]\n",
      "183+417 = 600  -> 500 \n",
      "150+488 = 638  -> 638 \n",
      "270+75  = 345  -> 1022\n",
      "665+546 = 1211 -> 1211\n",
      "381+432 = 813  -> 813 \n",
      "774+149 = 923  -> 923 \n",
      "419+675 = 1094 -> 1104\n",
      "958+155 = 1113 -> 1113\n",
      "337+75  = 412  -> 1092\n",
      "301+479 = 780  -> 780 \n"
     ]
    }
   ],
   "source": [
    "print(model3.evaluate(valid_X, valid_y))\n",
    "i = np.random.choice(valid_X.shape[0], 10, replace=False)\n",
    "sampleX, sampley = valid_X[i, :], valid_y[i]\n",
    "sampleyhat = model3.predict(sampleX)\n",
    "\n",
    "for x, y, yhat in zip(sampleX, sampley, sampleyhat):\n",
    "    print(decode(x), \"=\", decode(y), \"->\", decode(yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- The current keras version with Theano backend supports RNN dealing with varying length sequences. The tensorflow backend doesn't.\n",
    "- Even it is possible, training with varying length sequences should not be the first choice in most cases. As shown above, the most obvious way of doing so does introduce unstable factors in the training, which influences both the accuracy and convergence.\n",
    "- As a comparison, considering using a padding secheme for fixed-length seq2seq learning, with the same dataset, the performance of `model4` below is much better than any of solutions that I have explored.\n",
    "- However, it will be interesting to see new solutions proposed in this field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 28s - loss: 1.6365 - acc: 0.4071 - val_loss: 1.4667 - val_acc: 0.4623\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 28s - loss: 1.2561 - acc: 0.5365 - val_loss: 1.2408 - val_acc: 0.5315\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 28s - loss: 0.9538 - acc: 0.6421 - val_loss: 0.8140 - val_acc: 0.7015\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 28s - loss: 0.5489 - acc: 0.8088 - val_loss: 0.4617 - val_acc: 0.8565\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 28s - loss: 0.3365 - acc: 0.8928 - val_loss: 0.3091 - val_acc: 0.8992\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 28s - loss: 0.2244 - acc: 0.9311 - val_loss: 0.1965 - val_acc: 0.9418\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 29s - loss: 0.1656 - acc: 0.9484 - val_loss: 0.1776 - val_acc: 0.9399\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 28s - loss: 0.1293 - acc: 0.9593 - val_loss: 0.1255 - val_acc: 0.9611\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 28s - loss: 0.1071 - acc: 0.9667 - val_loss: 0.1051 - val_acc: 0.9669\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 29s - loss: 0.0863 - acc: 0.9730 - val_loss: 0.0842 - val_acc: 0.9728\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 30s - loss: 0.0808 - acc: 0.9755 - val_loss: 0.0682 - val_acc: 0.9798\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 30s - loss: 0.0634 - acc: 0.9799 - val_loss: 0.1213 - val_acc: 0.9550\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 31s - loss: 0.0611 - acc: 0.9808 - val_loss: 0.0629 - val_acc: 0.9794\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 30s - loss: 0.0504 - acc: 0.9846 - val_loss: 0.0594 - val_acc: 0.9804\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 27s - loss: 0.0528 - acc: 0.9837 - val_loss: 0.0654 - val_acc: 0.9780\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 30s - loss: 0.0523 - acc: 0.9835 - val_loss: 0.0437 - val_acc: 0.9860\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 30s - loss: 0.0348 - acc: 0.9897 - val_loss: 0.0490 - val_acc: 0.9844\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 31s - loss: 0.0438 - acc: 0.9870 - val_loss: 0.0386 - val_acc: 0.9875\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 31s - loss: 0.0337 - acc: 0.9895 - val_loss: 0.0550 - val_acc: 0.9828\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 31s - loss: 0.0443 - acc: 0.9863 - val_loss: 0.0239 - val_acc: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4dd871ebd0>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = create_model()\n",
    "train_X3 = np.array([encode(q, seqlen=7) for q in train_questions]) \n",
    "train_y3 = np.array([encode(a, seqlen=4) for a in train_answers]) \n",
    "\n",
    "model4.fit(train_X3, train_y3, nb_epoch=20, verbose = 1, validation_data=(valid_X, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s     \n",
      "[0.023949464198946953, 0.99355000000000004]\n",
      "567+662 = 1229 -> 1229\n",
      "304+653 = 957  -> 957 \n",
      "793+705 = 1498 -> 1498\n",
      "247+615 = 862  -> 862 \n",
      "200+308 = 508  -> 508 \n",
      "801+112 = 913  -> 913 \n",
      "9+563   = 572  -> 572 \n",
      "746+867 = 1613 -> 1613\n",
      "292+228 = 520  -> 520 \n",
      "848+465 = 1313 -> 1313\n"
     ]
    }
   ],
   "source": [
    "print(model4.evaluate(valid_X, valid_y))\n",
    "i = np.random.choice(valid_X.shape[0], 10, replace=False)\n",
    "sampleX, sampley = valid_X[i, :], valid_y[i]\n",
    "sampleyhat = model4.predict(sampleX)\n",
    "\n",
    "for x, y, yhat in zip(sampleX, sampley, sampleyhat):\n",
    "    print(decode(x), \"=\", decode(y), \"->\", decode(yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
